{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asymptotic Analysis\n",
    "\n",
    "In the previous section, we examined linear search and established a basis for analyzing algorithmic efficiency. Basically, we are concerned with how the number of operations of an algorithm grows as the problem size increases. We saw for linear search that we can express this as a function: $f(n) = c_1n + c_2n + c_4$\n",
    "\n",
    "This is exact, but it is tedious and it involves constants which depend on specific instructions and how quickly they execute on some specific hardware. From here, we want to simplify.\n",
    "\n",
    "Recall, algorithms are theoretical and exist independent of any programming language or computer they are executed on. The final result of our analysis shouldn't depend on instruction/machine constants. In essence, for linear search, we care that the runtime grows linearly, not the specific form of the line that it grows as. This is true in general, whether the runtime grows linearly, quadratically, or logarithmically, and we will see this with more examples.\n",
    "\n",
    "Before we get to these examples, we need to establish a set of notations for expressing algorithm runtimes in a simple manner and a framework for ranking runtimes so we can know which of multiple runtimes is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
